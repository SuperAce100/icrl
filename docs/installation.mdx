---
title: Installation
description: "How to install ICICL and its dependencies"
---

## Requirements

ICICL requires **Python 3.12** or higher.

## Installation

Install ICICL using your preferred package manager:

<CodeGroup>

```bash pip
pip install icicl
```

```bash uv
uv add icicl
```

```bash poetry
poetry add icicl
```

</CodeGroup>

## Dependencies

ICICL automatically installs the following dependencies:

| Package | Version | Purpose |
|---------|---------|---------|
| `pydantic` | ≥2.0.0 | Data validation and serialization |
| `litellm` | ≥1.0.0 | Unified LLM API for 100+ providers |
| `sentence-transformers` | ≥2.0.0 | Semantic embeddings for retrieval |
| `faiss-cpu` | ≥1.7.0 | Fast vector similarity search |
| `aiofiles` | ≥23.0.0 | Async file operations |
| `rich` | ≥13.0.0 | Terminal formatting |
| `python-dotenv` | ≥1.0.0 | Environment variable loading |

## API Keys

ICICL uses LiteLLM for LLM access, which supports [100+ providers](https://docs.litellm.ai/docs/providers). Configure your preferred provider:

<Tabs>
  <Tab title="OpenAI">
    ```bash
    export OPENAI_API_KEY=sk-...
    ```
    
    ```python
    from icicl import LiteLLMProvider
    
    llm = LiteLLMProvider(model="gpt-4o-mini")
    # or: gpt-4o, gpt-4-turbo, gpt-3.5-turbo
    ```
  </Tab>
  <Tab title="Anthropic">
    ```bash
    export ANTHROPIC_API_KEY=sk-ant-...
    ```
    
    ```python
    from icicl import LiteLLMProvider
    
    llm = LiteLLMProvider(model="claude-3-5-sonnet-20241022")
    # or: claude-3-opus-20240229, claude-3-haiku-20240307
    ```
  </Tab>
  <Tab title="Google">
    ```bash
    export GEMINI_API_KEY=...
    ```
    
    ```python
    from icicl import LiteLLMProvider
    
    llm = LiteLLMProvider(model="gemini/gemini-1.5-pro")
    # or: gemini/gemini-pro
    ```
  </Tab>
  <Tab title="Azure OpenAI">
    ```bash
    export AZURE_API_KEY=...
    export AZURE_API_BASE=https://your-resource.openai.azure.com
    export AZURE_API_VERSION=2024-02-15-preview
    ```
    
    ```python
    from icicl import LiteLLMProvider
    
    llm = LiteLLMProvider(model="azure/your-deployment-name")
    ```
  </Tab>
</Tabs>

## Using .env Files

You can also use a `.env` file in your project root:

```bash
# .env
OPENAI_API_KEY=sk-...
```

ICICL automatically loads environment variables from `.env` using `python-dotenv`.

## GPU Acceleration (Optional)

For faster embeddings with sentence-transformers, you can use GPU acceleration:

```bash
# Install PyTorch with CUDA support
pip install torch --index-url https://download.pytorch.org/whl/cu121

# Or with ROCm (AMD GPUs)
pip install torch --index-url https://download.pytorch.org/whl/rocm5.6
```

For GPU-accelerated FAISS:

```bash
# Replace faiss-cpu with faiss-gpu
pip uninstall faiss-cpu
pip install faiss-gpu
```

## Verify Installation

Run this script to verify everything is working:

```python
import icicl

print(f"ICICL version: {icicl.__version__}")

# Check if all components import correctly
from icicl import (
    Agent,
    LiteLLMProvider,
    Trajectory,
    Step,
    StepContext,
    Message,
    Environment,
    LLMProvider,
)

print("All components imported successfully!")

# Test embedding model loads
from icicl.embedder import SentenceTransformerEmbedder
embedder = SentenceTransformerEmbedder()
embedding = embedder.embed_single("test")
print(f"Embedding dimension: {len(embedding)}")

print("\n✓ Installation verified!")
```

## Development Installation

To install from source for development:

```bash
git clone https://github.com/SuperAce100/icicl.git
cd icicl

# Using uv (recommended)
uv sync

# Or using pip
pip install -e .
```

## Troubleshooting

<AccordionGroup>
  <Accordion title="ImportError: No module named 'faiss'">
    Make sure you have the CPU version installed:
    ```bash
    pip install faiss-cpu
    ```
    
    On some systems, you may need to install it first:
    ```bash
    pip uninstall faiss faiss-cpu faiss-gpu
    pip install faiss-cpu
    ```
  </Accordion>
  
  <Accordion title="sentence-transformers model download fails">
    The default model (`all-MiniLM-L6-v2`) is downloaded on first use. If you're behind a firewall:
    
    1. Download the model manually from [HuggingFace](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
    2. Set the cache directory:
    ```bash
    export SENTENCE_TRANSFORMERS_HOME=/path/to/models
    ```
  </Accordion>
  
  <Accordion title="LiteLLM API errors">
    Verify your API key is set correctly:
    ```python
    import os
    print(os.environ.get("OPENAI_API_KEY", "NOT SET"))
    ```
    
    Test the connection:
    ```python
    import litellm
    response = litellm.completion(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": "Hello"}]
    )
    print(response.choices[0].message.content)
    ```
  </Accordion>
</AccordionGroup>

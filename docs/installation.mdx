---
title: "Installation"
description: "Install ICRL and configure your environment for self-improving LLM agents"
---

## Requirements

ICRL requires **Python 3.12** or higher.

## Install ICRL

<Tabs>
  <Tab title="pip">
    ```bash
    pip install icrl
    ```
  </Tab>
  <Tab title="uv">
    ```bash
    uv add icrl
    ```
  </Tab>
  <Tab title="poetry">
    ```bash
    poetry add icrl
    ```
  </Tab>
</Tabs>

## Dependencies

ICRL automatically installs these dependencies:

| Package | Version | Purpose |
|---------|---------|---------|
| `pydantic` | ≥2.0.0 | Data validation and serialization |
| `litellm` | ≥1.0.0 | Unified LLM API for 100+ providers |
| `sentence-transformers` | ≥2.0.0 | Semantic embeddings for retrieval |
| `faiss-cpu` | ≥1.7.0 | Fast vector similarity search |
| `aiofiles` | ≥23.0.0 | Async file operations |
| `rich` | ≥13.0.0 | Terminal formatting |
| `python-dotenv` | ≥1.0.0 | Environment variable loading |

## Configure your LLM provider

ICRL uses LiteLLM for LLM access, which supports [100+ providers](https://docs.litellm.ai/docs/providers). Set up your preferred provider:

<Tabs>
  <Tab title="OpenAI">
    ```bash
    export OPENAI_API_KEY=sk-...
    ```
    
    ```python
    from icrl import LiteLLMProvider
    
    llm = LiteLLMProvider(model="gpt-4o-mini")
    # Other options: gpt-4o, gpt-4-turbo, gpt-3.5-turbo
    ```
  </Tab>
  <Tab title="Anthropic">
    ```bash
    export ANTHROPIC_API_KEY=sk-ant-...
    ```
    
    ```python
    from icrl import LiteLLMProvider
    
    llm = LiteLLMProvider(model="claude-3-5-sonnet-20241022")
    # Other options: claude-3-opus-20240229, claude-3-haiku-20240307
    ```
  </Tab>
  <Tab title="Google">
    ```bash
    export GEMINI_API_KEY=...
    ```
    
    ```python
    from icrl import LiteLLMProvider
    
    llm = LiteLLMProvider(model="gemini/gemini-1.5-pro")
    # Other options: gemini/gemini-pro
    ```
  </Tab>
  <Tab title="Azure OpenAI">
    ```bash
    export AZURE_API_KEY=...
    export AZURE_API_BASE=https://your-resource.openai.azure.com
    export AZURE_API_VERSION=2024-02-15-preview
    ```
    
    ```python
    from icrl import LiteLLMProvider
    
    llm = LiteLLMProvider(model="azure/your-deployment-name")
    ```
  </Tab>
</Tabs>

## Use .env files

You can store your API keys in a `.env` file in your project root:

```bash .env
OPENAI_API_KEY=sk-...
```

<Note>
ICRL automatically loads environment variables from `.env` using `python-dotenv`.
</Note>

## Optional: GPU acceleration

For faster embeddings with sentence-transformers, install PyTorch with GPU support:

<Tabs>
  <Tab title="NVIDIA (CUDA)">
    ```bash
    pip install torch --index-url https://download.pytorch.org/whl/cu121
    ```
  </Tab>
  <Tab title="AMD (ROCm)">
    ```bash
    pip install torch --index-url https://download.pytorch.org/whl/rocm5.6
    ```
  </Tab>
</Tabs>

For GPU-accelerated FAISS:

```bash
pip uninstall faiss-cpu
pip install faiss-gpu
```

## Verify your installation

Run this script to confirm everything works correctly:

```python verify.py
import icrl

print(f"ICRL version: {icrl.__version__}")

# Check if all components import correctly
from icrl import (
    Agent,
    LiteLLMProvider,
    Trajectory,
    Step,
    StepContext,
    Message,
    Environment,
    LLMProvider,
)

print("All components imported successfully!")

# Test embedding model loads
from icrl.embedder import SentenceTransformerEmbedder
embedder = SentenceTransformerEmbedder()
embedding = embedder.embed_single("test")
print(f"Embedding dimension: {len(embedding)}")

print("\n✓ Installation verified!")
```

<Check>
If you see "Installation verified!" your setup is complete and ready to use.
</Check>

## Development installation

To install from source for development:

<Steps>
  <Step title="Clone the repository">
    ```bash
    git clone https://github.com/SuperAce100/icrl.git
    cd icrl
    ```
  </Step>
  <Step title="Install dependencies">
    <Tabs>
      <Tab title="uv (recommended)">
        ```bash
        uv sync
        ```
      </Tab>
      <Tab title="pip">
        ```bash
        pip install -e .
        ```
      </Tab>
    </Tabs>
  </Step>
</Steps>

## Troubleshooting

<AccordionGroup>
  <Accordion title="ImportError: No module named 'faiss'">
    Reinstall the CPU version of FAISS:
    
    ```bash
    pip uninstall faiss faiss-cpu faiss-gpu
    pip install faiss-cpu
    ```
  </Accordion>
  
  <Accordion title="sentence-transformers model download fails">
    The default model (`all-MiniLM-L6-v2`) downloads on first use. If you're behind a firewall:
    
    1. Download the model manually from [HuggingFace](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
    2. Set the cache directory:
    
    ```bash
    export SENTENCE_TRANSFORMERS_HOME=/path/to/models
    ```
  </Accordion>
  
  <Accordion title="LiteLLM API errors">
    Verify your API key is set correctly:
    
    ```python
    import os
    print(os.environ.get("OPENAI_API_KEY", "NOT SET"))
    ```
    
    Test the connection directly:
    
    ```python
    import litellm
    response = litellm.completion(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": "Hello"}]
    )
    print(response.choices[0].message.content)
    ```
  </Accordion>
</AccordionGroup>

<Check>
Installation complete! Head to the [Quickstart guide](/quickstart) to build your first agent.
</Check>

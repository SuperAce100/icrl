---
title: "Harbor Coding Agent"
description: "Build a coding agent compatible with Harbor/Terminal-Bench 2.0 that improves through ICICL trajectory learning"
---

## Overview

This example demonstrates a coding agent that integrates with the [Harbor](https://harborframework.com) framework and Terminal-Bench 2.0. It shows how ICICL's self-generated in-context learning improves agent performance on realistic software engineering tasks.

<Note>
Harbor is the official harness for Terminal-Bench 2.0, a benchmark for evaluating AI agents on complex terminal-based tasks.
</Note>

## The Harbor Approach

Harbor agents operate in sandboxed environments where they execute shell commands to complete tasks. This example simulates that pattern:

```python
# Harbor-style agent interaction
async def run(instruction: str, environment: BaseEnvironment, context: AgentContext):
    """Run agent in sandboxed environment, populate context with results."""
    # Execute commands via environment.exec()
    # Track trajectory for learning
    pass
```

## Define the Coding Environment

Create a sandboxed coding environment that simulates a real development workspace:

```python coding_env.py
@dataclass
class CodingWorkspaceState:
    """State of the coding workspace (simulates Harbor sandbox)."""
    cwd: str = "/workspace"
    files: dict[str, str] = field(default_factory=dict)
    directories: set[str] = field(default_factory=set)
    shell_history: list[str] = field(default_factory=list)

class CodingEnvironment:
    """Coding environment compatible with ICICL Environment protocol."""
    
    def __init__(self, task: CodingTask):
        self._task = task
        self._state = CodingWorkspaceState()
        self._max_actions = 25
    
    def reset(self, goal: str) -> str:
        # Initialize realistic project structure
        self._state = CodingWorkspaceState(
            cwd="/workspace",
            files={
                "/workspace/src/main.py": "...",
                "/workspace/src/config.py": "...",
                "/workspace/tests/test_app.py": "...",
            },
            directories={"/workspace", "/workspace/src", "/workspace/tests"},
        )
        return f"Sandbox ready. Goal: {self._task.goal}"
    
    def step(self, action: str) -> tuple[str, bool, bool]:
        observation = self._execute_command(action)
        success = self._task.verify(self._state)
        return observation, success, success
```

## Define Coding Tasks

Create tasks that represent real software engineering work:

```python tasks.py
CODING_TASKS = {
    "training": [
        CodingTask(
            goal="Find the config.py file and identify the default port value",
            verify=lambda s: "8000" in s.last_output,
            difficulty="easy",
            category="code-analysis",
        ),
        CodingTask(
            goal="Fix the port configuration - change default from 8000 to 3000",
            verify=lambda s: "3000" in s.get_file_content("/workspace/src/config.py"),
            difficulty="medium", 
            category="debugging",
        ),
        CodingTask(
            goal="Add a test for the /api/data endpoint",
            verify=lambda s: "test_data_endpoint" in s.get_file_content("/workspace/tests/test_app.py"),
            difficulty="hard",
            category="testing",
        ),
    ],
    "evaluation": [
        CodingTask(
            goal="Find where the database URL is configured",
            verify=lambda s: "database_url" in s.last_output.lower(),
            difficulty="easy",
            category="code-analysis",
        ),
        CodingTask(
            goal="Fix the debug mode default - should be True for development",
            verify=lambda s: "debug: bool = True" in s.get_file_content("/workspace/src/config.py").lower(),
            difficulty="medium",
            category="debugging",
        ),
    ],
}
```

## Design Coding-Focused Prompts

Create prompts that guide the agent through software engineering tasks:

<CodeGroup>
```python plan_prompt.py
PLAN_PROMPT = """You are a skilled software engineer in a sandboxed coding environment.
You have access to standard shell commands to navigate, read, and modify code.

Goal: {goal}

Previous successful approaches to similar coding tasks:
{examples}

Create a concise, numbered plan to accomplish this goal. Consider:
1. What files you need to find or examine
2. What changes need to be made
3. How to verify the changes are correct"""
```

```python reason_prompt.py
REASON_PROMPT = """You are working on a coding task in a sandboxed environment.

Goal: {goal}
Your plan: {plan}
Previous steps: {history}
Current observation: {observation}

Similar situations from past experience:
{examples}

Analyze the current state:
- What did you learn from the last command output?
- Are you making progress toward the goal?
- What should be your next step?"""
```

```python act_prompt.py
ACT_PROMPT = """Goal: {goal}
Plan: {plan}
Steps so far: {history}
Current observation: {observation}
Your analysis: {reasoning}

Provide the SINGLE next shell command to execute.
Use standard Linux commands: ls, cd, cat, grep, find, sed, echo, etc.
Respond with ONLY the command, no explanation."""
```
</CodeGroup>

## Run the Performance Improvement Demo

The example demonstrates ICICL's value through three phases:

<Steps>
  <Step title="Baseline Evaluation">
    Test the agent on evaluation tasks without any learned examples:
    
    ```python
    baseline_success, baseline_trajectories = await run_baseline_evaluation(
        agent, CODING_TASKS["evaluation"]
    )
    # Results without ICICL training
    ```
  </Step>
  
  <Step title="Training Phase">
    Agent learns from successful trajectories on training tasks:
    
    ```python
    for task in CODING_TASKS["training"]:
        env = CodingEnvironment(task)
        trajectory = await agent.train(env, task.goal)
        # Successful trajectories are stored for future use
    ```
  </Step>
  
  <Step title="Improved Evaluation">
    Re-test on the same evaluation tasks with learned examples:
    
    ```python
    improved_success, improved_trajectories = await run_baseline_evaluation(
        agent, CODING_TASKS["evaluation"]
    )
    # Compare with baseline to measure improvement
    ```
  </Step>
</Steps>

## Complete Example

```python harbor_demo.py
#!/usr/bin/env python3
"""Harbor-compatible coding agent with ICICL performance improvement."""

import asyncio
import tempfile
from pathlib import Path

from examples.harbor_coding_agent import (
    CodingEnvironment,
    CODING_TASKS,
    PLAN_PROMPT,
    REASON_PROMPT,
    ACT_PROMPT,
)
from icicl import Agent, LiteLLMProvider

async def main():
    with tempfile.TemporaryDirectory() as tmpdir:
        agent = Agent(
            llm=LiteLLMProvider(model="gpt-4o-mini", temperature=0.3),
            db_path=str(Path(tmpdir) / "trajectories"),
            plan_prompt=PLAN_PROMPT,
            reason_prompt=REASON_PROMPT,
            act_prompt=ACT_PROMPT,
            k=3,
            max_steps=20,
        )
        
        # Phase 1: Baseline
        print("=== Baseline ===")
        for task in CODING_TASKS["evaluation"]:
            env = CodingEnvironment(task)
            traj = await agent.run(env, task.goal)
            print(f"{'✅' if traj.success else '❌'} {task.goal[:40]}...")
        
        # Phase 2: Training
        print("\n=== Training ===")
        for task in CODING_TASKS["training"]:
            env = CodingEnvironment(task)
            traj = await agent.train(env, task.goal)
            print(f"{'✅' if traj.success else '❌'} {task.goal[:40]}...")
        
        # Phase 3: Improved
        print("\n=== Post-Training ===")
        for task in CODING_TASKS["evaluation"]:
            env = CodingEnvironment(task)
            traj = await agent.run(env, task.goal)
            print(f"{'✅' if traj.success else '❌'} {task.goal[:40]}...")
        
        stats = agent.get_stats()
        print(f"\nStored trajectories: {stats['total_trajectories']}")

if __name__ == "__main__":
    asyncio.run(main())
```

## Run the Examples

<Steps>
  <Step title="With Real LLM">
    ```bash
    export OPENAI_API_KEY=your-key
    uv run python examples/harbor_coding_agent.py
    ```
  </Step>
  
  <Step title="Mock Version (No API Key)">
    ```bash
    uv run python examples/harbor_coding_mock.py
    ```
  </Step>
</Steps>

## Sample Output

```
╔═══════════════════════════════════════════════════════════╗
║  Harbor Coding Agent with ICICL Performance Improvement   ║
╚═══════════════════════════════════════════════════════════╝

═══ Phase 1: Baseline Evaluation (No Examples) ═══
Baseline Results: 1/3 tasks succeeded

═══ Phase 2: Training Phase ═══
Training 1/5: Find the config.py file...
  ✓ Success (3 steps)
Training 2/5: Fix the port configuration...
  ✓ Success (5 steps)
...

Training Summary:
  Tasks completed: 4/5
  Trajectories stored: 4

═══ Phase 3: Improved Evaluation (With Examples) ═══
Improved Results: 3/3 tasks succeeded

═══ Performance Comparison ═══
┌──────────────────────────────────────┬──────────┬───────────┐
│ Task                                 │ Baseline │ With ICICL│
├──────────────────────────────────────┼──────────┼───────────┤
│ Find where the database URL...       │    ✗     │     ✓     │
│ Fix the debug mode default...        │    ✗     │     ✓     │
│ Add input validation to...           │    ✓     │     ✓     │
└──────────────────────────────────────┴──────────┴───────────┘

✓ ICICL improved performance by 67%!
```

## Integration with Harbor

This example follows Harbor's agent patterns and can be extended for Terminal-Bench 2.0:

```python harbor_integration.py
from harbor.agents.base import BaseAgent
from harbor.environments.base import BaseEnvironment
from harbor.models.agent.context import AgentContext

class ICICLHarborAgent(BaseAgent):
    """ICICL-powered agent compatible with Harbor."""
    
    SUPPORTS_ATIF = True  # Support Harbor's trajectory format
    
    def __init__(self, icicl_agent: Agent, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.icicl_agent = icicl_agent
    
    @staticmethod
    def name() -> str:
        return "icicl-coding-agent"
    
    def version(self) -> str:
        return "1.0.0"
    
    async def setup(self, environment: BaseEnvironment) -> None:
        # Agent is ready to use, no installation needed
        pass
    
    async def run(
        self,
        instruction: str,
        environment: BaseEnvironment,
        context: AgentContext,
    ) -> None:
        # Wrap Harbor environment for ICICL
        icicl_env = HarborEnvironmentAdapter(environment, instruction)
        
        # Run with trajectory learning
        trajectory = await self.icicl_agent.run(icicl_env, instruction)
        
        # Populate Harbor context
        context.metadata = {
            "steps": len(trajectory.steps),
            "success": trajectory.success,
            "plan": trajectory.plan,
        }
```

## Key Takeaways

<CardGroup cols={2}>
  <Card title="Real Coding Tasks" icon="code">
    Tasks mirror actual software engineering work: debugging, testing, refactoring
  </Card>
  <Card title="Shell-Based Interface" icon="terminal">
    Agent uses familiar commands: ls, cat, grep, sed - matching Harbor's approach
  </Card>
  <Card title="Measurable Improvement" icon="chart-line">
    Clear before/after comparison shows ICICL's impact on performance
  </Card>
  <Card title="Harbor Compatible" icon="puzzle-piece">
    Follows Harbor's BaseAgent pattern for Terminal-Bench 2.0 integration
  </Card>
</CardGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Harbor Documentation" icon="book" href="https://harborframework.com/docs">
    Learn more about Harbor and Terminal-Bench 2.0
  </Card>
  <Card title="Custom Environments" icon="cube" href="/guides/custom-environments">
    Build environments for your specific use case
  </Card>
  <Card title="Batch Training" icon="layer-group" href="/guides/batch-training">
    Train on many tasks efficiently
  </Card>
  <Card title="File System Agent" icon="folder" href="/examples/file-system-agent">
    See the simpler file navigation example
  </Card>
</CardGroup>

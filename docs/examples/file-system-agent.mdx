---
title: "File System Agent"
description: "Build a complete ICRL agent that navigates a virtual file system to accomplish tasks"
---

## Overview

This example demonstrates a complete ICRL agent that navigates a simulated file system to accomplish tasks like finding files, reading contents, and copying data.

## Define the environment

First, create a simulated file system environment:

```python file_env.py
from pathlib import PurePosixPath
from dataclasses import dataclass, field
from collections.abc import Callable

@dataclass
class FileSystemState:
    """Tracks the current state of the virtual file system."""
    cwd: str = "/"
    last_output: str = ""
    files: dict[str, str] = field(default_factory=dict)
    directories: set[str] = field(default_factory=set)

@dataclass
class Task:
    """A verifiable task for the file system environment."""
    goal: str
    verify: Callable[[FileSystemState], bool]

class FileSystemEnvironment:
    """Simulated file system implementing the Environment protocol."""
    
    def __init__(self, task: Task):
        self._task = task
        self._state = FileSystemState()
        self._max_actions = 20
        self._action_count = 0
    
    def reset(self, goal: str) -> str:
        # Initialize virtual file tree
        self._state = FileSystemState(
            cwd="/",
            files={
                "/home/user/notes.txt": "Meeting notes:\n- Review code\n- Plan sprint",
                "/home/user/projects/main.py": 'print("Hello, World!")',
                "/etc/app/config.json": '{"port": 8080, "db_password": "secret123"}',
            },
            directories={
                "/", "/home", "/home/user", "/home/user/projects",
                "/etc", "/etc/app", "/backup", "/tmp",
            },
        )
        self._action_count = 0
        return f"Current directory: /\nGoal: {self._task.goal}"
    
    def step(self, action: str) -> tuple[str, bool, bool]:
        self._action_count += 1
        
        if self._action_count >= self._max_actions:
            return "Maximum actions reached.", True, False
        
        observation = self._execute_action(action)
        self._state.last_output = observation
        
        success = self._task.verify(self._state)
        if success:
            return f"{observation}\n[Task completed!]", True, True
        
        return observation, False, False
    
    def _execute_action(self, action: str) -> str:
        parts = action.strip().split(maxsplit=1)
        cmd = parts[0].lower() if parts else ""
        args = parts[1] if len(parts) > 1 else ""
        
        if cmd == "ls":
            return self._cmd_ls(args)
        elif cmd == "cd":
            return self._cmd_cd(args)
        elif cmd == "cat":
            return self._cmd_cat(args)
        elif cmd == "pwd":
            return self._state.cwd
        elif cmd == "find":
            return self._cmd_find(args)
        elif cmd == "cp":
            return self._cmd_cp(args)
        else:
            return f"Unknown command: {cmd}"
    
    # Command implementations...
```

<Note>
See `examples/file_api_env.py` in the repository for the complete implementation with all command handlers.
</Note>

## Define tasks

Create tasks with goals and verification functions:

```python tasks.py
# Easy tasks
easy_tasks = [
    Task(
        goal="Navigate to /home/user/projects and list the files",
        verify=lambda s: s.cwd == "/home/user/projects" and "main.py" in s.last_output,
    ),
    Task(
        goal="Find the database password in the config files",
        verify=lambda s: "secret123" in s.last_output,
    ),
]

# Hard tasks
hard_tasks = [
    Task(
        goal="Copy notes.txt to the /backup directory",
        verify=lambda s: s.file_exists("/backup/notes.txt"),
    ),
    Task(
        goal="Find main.py and copy it to /backup",
        verify=lambda s: s.file_exists("/backup/main.py"),
    ),
]
```

## Create prompt templates

Design prompts that describe available commands and guide the agent:

<CodeGroup>
```python plan_prompt.py
PLAN_PROMPT = """You are a file system navigation agent. Available commands:
- ls [dir] - list directory contents
- cd <dir> - change directory
- cat <file> - display file contents
- find <pattern> - search for files
- pwd - print working directory
- mkdir <name> - create directory
- cp <src> <dst> - copy file

Goal: {goal}

Previous successful examples:
{examples}

Create a brief, numbered plan to accomplish the goal."""
```

```python reason_prompt.py
REASON_PROMPT = """You are navigating a file system.

Goal: {goal}
Your plan: {plan}

Previous steps:
{history}

Current observation: {observation}

Examples from similar situations:
{examples}

Think step by step: What did you observe? What should you do next?"""
```

```python act_prompt.py
ACT_PROMPT = """Goal: {goal}
Plan: {plan}
History: {history}
Observation: {observation}
Reasoning: {reasoning}

What is the SINGLE next command? Respond with only the command."""
```
</CodeGroup>

## Create the agent

<Steps>
  <Step title="Set up the step callback">
    Monitor what your agent does in real-time:
    
    ```python callback.py
    from icrl import Step, StepContext

    def on_step(step: Step, context: StepContext) -> None:
        print(f"\nüìç Observation: {step.observation[:100]}...")
        print(f"ü§î Reasoning: {step.reasoning[:100]}...")
        print(f"‚ñ∂Ô∏è Action: {step.action}")
        print(f"üìö Examples: {len(context.examples)}")
    ```
  </Step>
  
  <Step title="Initialize the agent">
    ```python agent.py
    from icrl import Agent, LiteLLMProvider

    agent = Agent(
        llm=LiteLLMProvider(model="gpt-4o-mini", temperature=0.3),
        db_path="./file_agent_trajectories",
        plan_prompt=PLAN_PROMPT,
        reason_prompt=REASON_PROMPT,
        act_prompt=ACT_PROMPT,
        k=2,
        max_steps=15,
        on_step=on_step,
    )
    ```
    
    <Check>
    Your agent is ready. The `k=2` setting retrieves 2 examples at each decision point.
    </Check>
  </Step>
</Steps>

## Train the agent

```python train.py
async def train_agent():
    print("=== Training Phase ===")
    
    training_tasks = [
        Task(goal="Navigate to /home/user and list files", 
             verify=lambda s: s.cwd == "/home/user"),
        Task(goal="Find the port number in /etc/app/config.json",
             verify=lambda s: "8080" in s.last_output),
        Task(goal="Copy notes.txt from /home/user to /backup",
             verify=lambda s: s.file_exists("/backup/notes.txt")),
    ]
    
    for i, task in enumerate(training_tasks, 1):
        print(f"\n--- Task {i}/{len(training_tasks)} ---")
        print(f"Goal: {task.goal}")
        
        env = FileSystemEnvironment(task)
        trajectory = await agent.train(env, task.goal)
        
        if trajectory.success:
            print(f"‚úÖ Success in {len(trajectory.steps)} steps")
        else:
            print(f"‚ùå Failed after {len(trajectory.steps)} steps")
    
    stats = agent.get_stats()
    print(f"\nStored: {stats['total_trajectories']} trajectories")
    print(f"Success rate: {stats['success_rate']:.1%}")

asyncio.run(train_agent())
```

## Evaluate on new tasks

Test on held-out tasks to measure generalization:

```python evaluate.py
async def evaluate_agent():
    print("\n=== Evaluation Phase ===")
    
    eval_tasks = [
        Task(goal="Find all Python files in the system",
             verify=lambda s: "main.py" in s.last_output),
        Task(goal="Read the contents of the config file in /etc/app",
             verify=lambda s: "port" in s.last_output),
    ]
    
    results = []
    for task in eval_tasks:
        print(f"\nGoal: {task.goal}")
        
        # Show what examples will be retrieved
        similar = agent.database.search(task.goal, k=2)
        if similar:
            print("Retrieved examples:")
            for s in similar:
                print(f"  - {s.goal[:50]}...")
        
        env = FileSystemEnvironment(task)
        trajectory = await agent.run(env, task.goal)  # Inference mode
        
        results.append(trajectory.success)
        print(f"Result: {'‚úÖ Success' if trajectory.success else '‚ùå Failed'}")
    
    print(f"\nEval accuracy: {sum(results)}/{len(results)}")

asyncio.run(evaluate_agent())
```

## Complete runnable script

```python demo.py
#!/usr/bin/env python3
"""File system navigation agent with ICRL."""

import asyncio
import os
import tempfile
from pathlib import Path

from dotenv import load_dotenv

from examples.file_api_env import FileSystemEnvironment, Task
from icrl import Agent, LiteLLMProvider, Step, StepContext

load_dotenv()

PLAN_PROMPT = """You are a file system navigation agent. Commands:
- ls [dir], cd <dir>, cat <file>, find <pattern>, pwd, mkdir <name>, cp <src> <dst>

Goal: {goal}

Examples:
{examples}

Create a numbered plan."""

REASON_PROMPT = """Goal: {goal}
Plan: {plan}
History: {history}
Observation: {observation}
Examples: {examples}

Think step by step about what to do next."""

ACT_PROMPT = """Goal: {goal}
Plan: {plan}
Reasoning: {reasoning}

Next command (only the command):"""


def on_step(step: Step, context: StepContext) -> None:
    print(f"  Action: {step.action}")


async def main():
    with tempfile.TemporaryDirectory() as tmpdir:
        agent = Agent(
            llm=LiteLLMProvider(
                model=os.environ.get("MODEL", "gpt-4o-mini"),
                temperature=0.3,
            ),
            db_path=str(Path(tmpdir) / "trajectories"),
            plan_prompt=PLAN_PROMPT,
            reason_prompt=REASON_PROMPT,
            act_prompt=ACT_PROMPT,
            k=2,
            max_steps=15,
            on_step=on_step,
        )
        
        # Training
        training_tasks = [
            Task(
                goal="Navigate to /home/user/projects and list files",
                verify=lambda s: s.cwd == "/home/user/projects",
            ),
            Task(
                goal="Find the database password in the config files",
                verify=lambda s: "secret123" in s.last_output,
            ),
        ]
        
        print("=== Training ===")
        for task in training_tasks:
            print(f"\nGoal: {task.goal}")
            env = FileSystemEnvironment(task)
            traj = await agent.train(env, task.goal)
            print(f"Result: {'‚úÖ' if traj.success else '‚ùå'}")
        
        # Evaluation
        eval_task = Task(
            goal="Find the port number in the config",
            verify=lambda s: "8080" in s.last_output,
        )
        
        print("\n=== Evaluation ===")
        print(f"Goal: {eval_task.goal}")
        env = FileSystemEnvironment(eval_task)
        traj = await agent.run(env, eval_task.goal)
        print(f"Result: {'‚úÖ' if traj.success else '‚ùå'}")
        
        stats = agent.get_stats()
        print(f"\nDatabase: {stats['total_trajectories']} trajectories")


if __name__ == "__main__":
    asyncio.run(main())
```

## Run the example

<Steps>
  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=your-key
    ```
  </Step>
  
  <Step title="Run the demo">
    ```bash
    cd /path/to/icrl
    uv run python examples/demo_with_real_llm.py
    ```
  </Step>
</Steps>

## Sample output

```
=== Training ===

Goal: Navigate to /home/user/projects and list files
  Action: cd /home/user/projects
  Action: ls
Result: ‚úÖ

Goal: Find the database password in the config files
  Action: cd /etc/app
  Action: cat config.json
Result: ‚úÖ

=== Evaluation ===
Goal: Find the port number in the config
  Action: cd /etc/app
  Action: cat config.json
Result: ‚úÖ

Database: 2 trajectories
```

<Check>
Your agent learned from training tasks and successfully applied that knowledge to a new evaluation task!
</Check>

## Key takeaways

<CardGroup cols={2}>
  <Card title="Environment design" icon="cube">
    Clear observations and verifiable success conditions make training effective
  </Card>
  <Card title="Prompt engineering" icon="message">
    Specific commands and structured thinking guides produce better results
  </Card>
  <Card title="Training first" icon="graduation-cap">
    Build up examples before evaluation to leverage in-context learning
  </Card>
  <Card title="Retrieval helps" icon="magnifying-glass">
    Similar past experiences improve performance on new tasks
  </Card>
</CardGroup>

## Next steps

<CardGroup cols={2}>
  <Card title="Custom Environments" icon="puzzle-piece" href="/guides/custom-environments">
    Build environments for your use case
  </Card>
  <Card title="Prompt Templates" icon="message" href="/guides/prompt-templates">
    Design effective prompts
  </Card>
  <Card title="Batch Training" icon="layer-group" href="/guides/batch-training">
    Train on many tasks efficiently
  </Card>
  <Card title="Testing with Mock LLM" icon="flask" href="/examples/testing-with-mock-llm">
    Fast iteration without API calls
  </Card>
</CardGroup>
